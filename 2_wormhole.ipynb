{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e281a43d-fabb-4510-9c80-c8a0bbbe6524",
   "metadata": {},
   "source": [
    "### Chapter 2 - Wormhole\n",
    "- Seperate notebook for rendering landscapes while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210800ec-e50e-42f5-a040-c06062de9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers matplotlib tqdm huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547f0c2-52f5-42a9-85be-f4fd40c52e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b3fd07-c9d5-44a0-a97f-fa24f1c8b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast, LlamaConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c263c22-47cd-41d3-8d29-43a58b0bf239",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "#Pretrained\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a98ec-fa6c-4e74-8a49-37fe6970cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confgiruation for this run\n",
    "output_dir='/workspace/apr_26_2'\n",
    "num_points=32 \n",
    "n_steps=128 \n",
    "lr=1e-7\n",
    "delayed_viz_start=0 #e.g. set to 10 if i only want to start renderding after the 10th optimiation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dada6-d1b8-490e-9862-8af81b688d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_directions(params, seed=None):\n",
    "    \"\"\"\n",
    "    Generate random direction vectors for each parameter tensor.\n",
    "    \n",
    "    Args:\n",
    "        params: List of (name, parameter) tuples from model.named_parameters()\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        direction: OrderedDict mapping parameter names to random direction tensors\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    direction = OrderedDict()\n",
    "    for name, param in params:\n",
    "        if param.requires_grad:\n",
    "            direction[name] = torch.randn_like(param.data)\n",
    "    \n",
    "    return direction\n",
    "\n",
    "def normalize_direction(direction, params):\n",
    "    \"\"\"\n",
    "    Normalize the direction tensors to match the norm of each parameter tensor.\n",
    "    \n",
    "    Args:\n",
    "        direction: OrderedDict mapping parameter names to direction tensors\n",
    "        params: List of (name, parameter) tuples from model.named_parameters()\n",
    "        \n",
    "    Returns:\n",
    "        normalized_direction: OrderedDict with normalized direction tensors\n",
    "    \"\"\"\n",
    "    param_dict = OrderedDict(params)\n",
    "    normalized_direction = OrderedDict()\n",
    "    \n",
    "    for name, dir_tensor in direction.items():\n",
    "        param_norm = torch.norm(param_dict[name].data)\n",
    "        dir_norm = torch.norm(dir_tensor)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if dir_norm > 0:\n",
    "            normalized_direction[name] = dir_tensor * (param_norm / dir_norm)\n",
    "        else:\n",
    "            normalized_direction[name] = dir_tensor\n",
    "    \n",
    "    return normalized_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1325b-fcbb-4373-b75d-a2e3d1465141",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The capital of France is Paris\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12793e9-fa70-4c33-8ff8-b89092cd4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "y_one_hot=F.one_hot(input_ids, num_classes=model.config.vocab_size)\n",
    "correct_next_token_probs = (my_probs[:,:-1]*y_one_hot[:,1:]).sum(-1) \n",
    "my_loss=-torch.log(correct_next_token_probs).mean()\n",
    "print(my_loss.item(), outputs.loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89a338-07d0-46bb-bb09-d5d152dbca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "y_one_hot=F.one_hot(input_ids, num_classes=model.config.vocab_size)\n",
    "correct_next_token_probs = (my_probs[:,:-1]*y_one_hot[:,1:]).sum(-1) \n",
    "my_loss=-torch.log(correct_next_token_probs).mean()\n",
    "\n",
    "paris_only_loss=-np.log(my_probs[0, 5, 12366].item())\n",
    "print(my_loss.item(), outputs.loss.item(), paris_only_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ee5c8-9c6e-4ed3-9b7b-a3c5fd2867a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sI=np.argsort(my_probs[0,5, :].detach().cpu().float().numpy())[::-1]\n",
    "for i in sI[:10]:\n",
    "    print(i, round(my_probs[0, 5, i].item(),5), tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd954ca-9ef4-4d44-a549-223b5e7ef812",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix='pretrained_'\n",
    "filtered_params = [(name, p) for name, p in model.named_parameters() if p.requires_grad]\n",
    "# layers_name='all'\n",
    "\n",
    "layers_name='first_8'\n",
    "filtered_params = filtered_params[1:73] \n",
    "\n",
    "# layers_name='last_8'\n",
    "# filtered_params = filtered_params[73:] #Last 8 layers - some nice structue, but yeah more parabolic than I would like\n",
    "\n",
    "random_seed_1=11\n",
    "random_seed_2=111\n",
    "\n",
    "# Generate and normalize random directions\n",
    "direction1 = get_random_directions(filtered_params, seed=random_seed_1)\n",
    "direction2 = get_random_directions(filtered_params, seed=random_seed_2)\n",
    "\n",
    "direction1 = normalize_direction(direction1, filtered_params)\n",
    "direction2 = normalize_direction(direction2, filtered_params)\n",
    "\n",
    "original_params = OrderedDict()\n",
    "for name, param in filtered_params:\n",
    "    original_params[name] = param.data.clone()\n",
    "\n",
    "alphas=np.linspace(-2.5, 2.5, num_points)\n",
    "betas=np.linspace(-2.5, 2.5, num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82941fe6-2bb9-45ca-9be4-a95678a6fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a999b-c0c6-4f8f-ac83-0e9aab691460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move away from center\n",
    "alpha_shift=-0.9 \n",
    "beta_shift=0.05\n",
    "\n",
    "alphas_shifted=alphas-alpha_shift #Shift scan points to keep thing consistent. \n",
    "betas_shifted=betas-beta_shift\n",
    "\n",
    "#Replace actual model parameters with the shifted ones. \n",
    "for name, param in model.named_parameters():\n",
    "    if name in direction1 and name in direction2:\n",
    "        param.data = original_params[name] + alpha_shift * direction1[name] + beta_shift * direction2[name]\n",
    "\n",
    "#Make copy for scaning/replacing. \n",
    "original_params_shifted = OrderedDict()\n",
    "for name, param in filtered_params:\n",
    "    original_params_shifted[name] = param.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13d4a1-e2d4-4388-800c-76619ba4c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs=[]\n",
    "for step in range(n_steps):\n",
    "    losses=[]\n",
    "    model.eval();\n",
    "\n",
    "    with torch.no_grad(): #Check current outputs\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "        sI=np.argsort(my_probs[0,5, :].detach().cpu().float().numpy())[::-1]\n",
    "        current_outs=[[12366,  round(my_probs[0, 5, 12366].item(), 7), ' Paris']] #Put paris at top\n",
    "        for i in sI[:10]:\n",
    "            current_outs.append([i, round(my_probs[0, 5, i].item(),7), tokenizer.decode([i])])\n",
    "        model_outputs.append(current_outs)\n",
    "        print(step, 'loss=', -np.log(my_probs[0, 5, 12366].item()), current_outs[0], current_outs[1])\n",
    "\n",
    "    if step>=delayed_viz_start: #Do I want to compute loss landscape at this step?\n",
    "        with torch.no_grad():\n",
    "            for i, alpha in enumerate(tqdm(alphas_shifted)):\n",
    "                losses.append([])\n",
    "                for j, beta in enumerate(betas_shifted):\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if name in direction1:\n",
    "                            param.data = original_params_shifted[name] + alpha * direction1[name] + beta*direction2[name]\n",
    "                    \n",
    "                    outputs = model(input_ids, labels=input_ids)\n",
    "                    my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "                    paris_only_loss=-np.log(my_probs[0, 5, 12366].item()) #Just Paris\n",
    "                    losses[-1].append(paris_only_loss)\n",
    "            \n",
    "            for name, param in model.named_parameters(): # Restore original shifted parameters\n",
    "                if name in original_params: \n",
    "                    param.data.copy_(original_params_shifted[name])\n",
    "        losses=np.array(losses)\n",
    "        np.save(output_dir +'/'+str(step).zfill(3), losses) #Save loss landscape\n",
    "        \n",
    "        plt.clf()\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        contourf = ax.contourf(alphas, betas, losses, 20, cmap='viridis', alpha=0.8)\n",
    "        contour = ax.contour(alphas, betas, losses, 30, colors='white', linewidths=0.5)\n",
    "        plt.scatter(beta_shift, alpha_shift, c='m')\n",
    "        plt.savefig(output_dir +'/'+str(step).zfill(3)+'.png')\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    loss = outputs.loss #Ok not just paris loss here -> not sure how much I'm worried about that\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #After training I need to replace original_params_shifted with the new trained values\n",
    "    original_params_shifted = OrderedDict()\n",
    "    for name, param in filtered_params:\n",
    "        original_params_shifted[name] = param.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ac0bd-2f20-4225-93ff-bdfe59b9ca0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cae6b0-f9c5-4316-8683-4fcaf1fe233b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1d2f3-1820-4ea7-a1db-3ec2a970d74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
